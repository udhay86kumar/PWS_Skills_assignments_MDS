{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b27f51f2-51d2-489b-aed9-7fcdb4f4393c",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA) QnA\n",
    "\n",
    "# Question 1: What is a projection and how is it used in PCA?\n",
    "\"\"\"\n",
    "A projection in PCA refers to mapping high-dimensional data onto a lower-dimensional subspace.\n",
    "It helps in reducing the dimensionality while preserving the most important features.\n",
    "\"\"\"\n",
    "\n",
    "# Question 2: How does the optimization problem in PCA work, and what is it trying to achieve?\n",
    "\"\"\"\n",
    "PCA solves an optimization problem to find the principal components that maximize the variance of the data.\n",
    "It does this by solving an eigenvalue problem on the covariance matrix.\n",
    "\"\"\"\n",
    "\n",
    "# Question 3: What is the relationship between covariance matrices and PCA?\n",
    "\"\"\"\n",
    "The covariance matrix captures the relationships between different features.\n",
    "PCA diagonalizes the covariance matrix to obtain eigenvalues and eigenvectors, which determine principal components.\n",
    "\"\"\"\n",
    "\n",
    "# Question 4: How does the choice of number of principal components impact the performance of PCA?\n",
    "\"\"\"\n",
    "Choosing more components retains more information but may lead to overfitting.\n",
    "Choosing fewer components improves efficiency but may lose important patterns.\n",
    "\"\"\"\n",
    "\n",
    "# Question 5: How can PCA be used in feature selection, and what are the benefits of using it for this purpose?\n",
    "\"\"\"\n",
    "PCA selects the most important features by reducing dimensions while preserving variance.\n",
    "Benefits include noise reduction, improved model performance, and reduced computational cost.\n",
    "\"\"\"\n",
    "\n",
    "# Question 6: What are some common applications of PCA in data science and machine learning?\n",
    "\"\"\"\n",
    "Common applications include:\n",
    "- Image compression\n",
    "- Noise reduction\n",
    "- Feature extraction for machine learning models\n",
    "- Exploratory data analysis\n",
    "\"\"\"\n",
    "\n",
    "# Question 7: What is the relationship between spread and variance in PCA?\n",
    "\"\"\"\n",
    "Variance measures the spread of data in each direction.\n",
    "PCA selects principal components based on the directions with the highest variance.\n",
    "\"\"\"\n",
    "\n",
    "# Question 8: How does PCA use the spread and variance of the data to identify principal components?\n",
    "\"\"\"\n",
    "PCA identifies directions (eigenvectors) where the variance (spread) is maximized.\n",
    "These directions define the principal components.\n",
    "\"\"\"\n",
    "\n",
    "# Question 9: How does PCA handle data with high variance in some dimensions but low variance in others?\n",
    "\"\"\"\n",
    "PCA gives more importance to high-variance dimensions while reducing the impact of low-variance dimensions.\n",
    "This ensures that the principal components retain the most useful information.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
