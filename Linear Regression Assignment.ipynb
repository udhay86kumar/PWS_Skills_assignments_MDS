{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8eb7322",
   "metadata": {},
   "source": [
    "### Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c3800",
   "metadata": {},
   "source": [
    "### Simple Linear Regression:\n",
    "\n",
    "Simple Linear Regression involves predicting a dependent variable y based on a single independent variable x. The relationship between x and y is modeled as a straight line:\n",
    "\n",
    "- y=mx+b\n",
    "\n",
    "- y is the dependent variable.\n",
    "\n",
    "- x is the independent variable.\n",
    "\n",
    "- m is the slope of the line.\n",
    "\n",
    "- b is the y-intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deeae9a",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression:\n",
    "\n",
    "Multiple Linear Regression extends the concept of linear regression to multiple independent variables. The relationship between the dependent variable  y and multiple independent variables x1,x2,x3,...xn... modeled as..\n",
    "\n",
    "y=b0+b1X1+b2X2+…+bnXn\n",
    "\n",
    "- y is the dependent variable.\n",
    "- x1,x2,...xn are multiple independent variables.\n",
    "- b0 is the y-intercept.\n",
    "- b1,b2,...,bn are the coefficients associated with each independent variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfa29e2",
   "metadata": {},
   "source": [
    "## Key Differences:\n",
    "\n",
    "### Number of Independent Variables:\n",
    "\n",
    "- Simple Linear Regression involves one independent variable.\n",
    "- Multiple Linear Regression involves two or more independent variables.\n",
    "\n",
    "#### Equation:\n",
    "\n",
    "#### Simple Linear Regression: \n",
    "- y=mx+b\n",
    "\n",
    "#### Multiple Linear Regression: \n",
    "- y=b0+b1X1+b2X2+…+bnXn\n",
    "\n",
    "#### Complexity:\n",
    "- Simple Linear Regression is simpler but may not capture complex relationships.\n",
    "- Multiple Linear Regression can model more complex relationships with multiple factors.\n",
    "\n",
    "#### Use Cases:\n",
    "\n",
    "- Simple Linear Regression is suitable when there is a clear relationship between two variables.\n",
    "- Multiple Linear Regression is used when multiple factors influence the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec898f",
   "metadata": {},
   "source": [
    "### Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b80152",
   "metadata": {},
   "source": [
    "## Assumptions of Linear Regression:\n",
    "\n",
    "Linear regression makes several assumptions about the data and the relationship between the variables. It's important to be aware of these assumptions when applying linear regression models:\n",
    "\n",
    "### Linearity:\n",
    "\n",
    "The relationship between the independent and dependent variables is linear. The model assumes that a change in the independent variable results in a constant change in the dependent variable.\n",
    "\n",
    "### Independence:\n",
    "\n",
    "The residuals (the differences between actual and predicted values) are independent. In other words, the value of the dependent variable for one observation does not depend on the values of the dependent variable for other observations.\n",
    "\n",
    "### Homoscedasticity:\n",
    "\n",
    "The variance of the residuals is constant across all levels of the independent variable(s). This assumption implies that the spread of residuals should be roughly the same throughout the range of predicted values.\n",
    "\n",
    "### Normality of Residuals:\n",
    "\n",
    "The residuals are normally distributed. While this assumption is not strictly necessary for large sample sizes due to the Central Limit Theorem, it can be important for smaller sample sizes.\n",
    "\n",
    "### No Perfect Multicollinearity:\n",
    "\n",
    "There should not be perfect linear relationships among the independent variables. Multicollinearity can make it difficult to isolate the individual effect of each variable on the dependent variable.\n",
    "\n",
    "## Checking Assumptions:\n",
    "\n",
    "### Residuals vs. Fitted Values Plot:\n",
    "\n",
    "Plot residuals against the predicted values. Look for a random pattern with no clear trend. This helps assess linearity and homoscedasticity.\n",
    "\n",
    "### Normal Q-Q Plot:\n",
    "\n",
    "Check if the residuals follow a roughly straight line in a quantile-quantile plot. This helps assess the normality of residuals.\n",
    "\n",
    "### Residuals Autocorrelation:\n",
    "\n",
    "Examine the residuals for autocorrelation using a correlogram or the Durbin-Watson statistic. Independence assumption is violated if autocorrelation is present.\n",
    "\n",
    "### VIF (Variance Inflation Factor):\n",
    "\n",
    "Calculate VIF for each independent variable to check for multicollinearity. High VIF values indicate potential multicollinearity issues.\n",
    "\n",
    "### Cook's Distance:\n",
    "\n",
    "Identify influential data points using Cook's distance. High values may indicate observations that strongly affect the regression results.\n",
    "\n",
    "### Histogram of Residuals:\n",
    "\n",
    "Check for a normal distribution of residuals using a histogram.\n",
    "\n",
    "### Shapiro-Wilk Test:\n",
    "\n",
    "Use the Shapiro-Wilk test to formally test the normality of residuals.\n",
    "\n",
    "### Heteroscedasticity Tests:\n",
    "\n",
    "Perform statistical tests for heteroscedasticity, such as the Breusch-Pagan test or the White test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ee933",
   "metadata": {},
   "source": [
    "### Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d32511",
   "metadata": {},
   "source": [
    "### Interpretation of Slope and Intercept in Linear Regression:\n",
    "\n",
    "In a linear regression model, the equation is typically represented as:\n",
    "Dependent Variable = Intercept + Slope × Independent Variable + Error\n",
    "Dependent Variable=Intercept+Slope×Independent Variable+Error\n",
    "\n",
    "Here's how to interpret the slope (b1) and intercept (b0):\n",
    "\n",
    "### Intercept ( b0 ):\n",
    "\n",
    "Represents the estimated value of the dependent variable when the independent variable(s) is zero.\n",
    "It's the value of the dependent variable when all independent variables are absent or equal to zero.\n",
    "In some cases, the interpretation may not make sense if zero is not a meaningful value for the independent variable.\n",
    "\n",
    "### Slope (b1):\n",
    "\n",
    "Represents the change in the dependent variable for a one-unit change in the independent variable.\n",
    "Indicates the degree and direction of the linear relationship between the variables.\n",
    "\n",
    "#### Positive slope (1>b>0): \n",
    "- As the independent variable increases, the dependent variable is expected to increase.\n",
    "\n",
    "#### Negative slope (1<b1<0):\n",
    "- As the independent variable increases, the dependent variable is expected to decrease.\n",
    "Example: Predicting Salary Based on Years of Experience\n",
    "\n",
    "Consider a real-world scenario where you want to predict an individual's salary (y) based on the number of years of experience (x). The linear regression model might look like:\n",
    "\n",
    "\n",
    "Salary=0+1×Years of Experience+Error\n",
    "Salary=b0+b1×Years of Experience+Error\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "The intercept (b0) represents the estimated salary when an individual has zero years of experience. It could be the starting salary.\n",
    "\n",
    "The slope (b1) represents the estimated change in salary for a one-year increase in experience. For example, if b1 is $5,000, it means, on average, each additional year of experience is associated with a $5,000 increase in salary.\n",
    "So, for a person with 3 years of experience, the predicted salary would be \n",
    "0+3×b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "# Generate synthetic data\n",
    "data = {'Years_of_Experience': [2, 4, 6, 8, 10],\n",
    "        'Salary': [50000, 60000, 75000, 90000, 110000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add a constant for the intercept\n",
    "X = sm.add_constant(df['Years_of_Experience'])\n",
    "y = df['Salary']\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary to see the coefficients\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2645f41d",
   "metadata": {},
   "source": [
    "## Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5905992",
   "metadata": {},
   "source": [
    "## Gradient Descent:\n",
    "\n",
    "Gradient Descent is an iterative optimization algorithm used to find the minimum of a function. In the context of machine learning, it is commonly used to minimize the cost or loss function associated with training a model. The idea is to adjust the parameters of the model iteratively in the direction that reduces the cost until a minimum is reached.\n",
    "\n",
    "Here's a step-by-step explanation:\n",
    "\n",
    "Initialize Parameters:\n",
    "\n",
    "Start with initial values for the parameters of the model.\n",
    "Compute the Gradient:\n",
    "\n",
    "Calculate the gradient (partial derivatives) of the cost function with respect to each parameter.\n",
    "The gradient indicates the direction of the steepest ascent.\n",
    "Update Parameters:\n",
    "\n",
    "Adjust the parameters in the opposite direction of the gradient to move towards the minimum.\n",
    "The learning rate (α) controls the size of the steps taken in each iteration.\n",
    "Repeat:\n",
    "\n",
    "Repeat steps 2 and 3 until convergence or a predefined number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5b141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34306a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de035984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f1b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
